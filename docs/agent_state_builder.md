# AgentStateBuilder

## Conceptual Guide: Grounding the LLM and mapping context to an Agent State

One of the biggest challenges in building intelligent LLM applications is delivering the **right context** to the model at the **right time**.

LLMs â€” like humans â€” can't reason intelligently without the proper context for a given situation.

---

### ğŸ§  A Simple Example

Imagine a student asks an LLM:  
> â€œWhatâ€™s a vector?â€

The LLM replies:
> â€œA vector is a fundamental mathematical unit that has both magnitude and direction.â€

Technically correctâ€¦ but not helpful if the student is working on a **C++ project**, not a physics assignment.

With that additional context (i.e. "I'm a C++ student writing code"), the LLM might instead reply:
> â€œIn C++, a `vector` is a dynamic array provided by the STL (Standard Template Library)...â€

This is the power of **grounding** â€” giving the model relevant context *before* it generates a response.

---

## ğŸ§© What is `AgentStateBuilder`?

The `AgentStateBuilder` is a simple yet powerful pattern to **inject additional context** into the agentâ€™s input before invoking the LangGraph agent.

It acts as a bridge between:
- User input (e.g., chat messages, form fields, etc.)
- Application state (e.g., database values, page content, environment context)

This creates a richer state object that is passed into the LangGraph run.

---

### ğŸ›  Real-World Use Case: LlamaPress

In our product **LlamaPress**, users can build and edit webpages using natural language.

When a user says:
> â€œPlease change the hero sectionâ€™s background to pinkâ€

The LLM needs to know:
- What page the user is referring to
- What the current HTML structure looks like
- Any relevant metadata or UI context

So we inject a structured payload like:

```json
{
  "message": "Please change the hero section's background to pink",
  "web_page_content": "<!DOCTYPE html><html><body>...</body></html>"
}

This lets the LLM reason about the environment â€” not just the request.

### âœ¨ Why It Matters

Most LLM failures stem from one thing: lack of context.

By giving your agent a clean, extensible interface to inject state, youâ€™re enabling:

Fewer hallucinations

Smarter responses

More agentic behavior

Higher reliability

The AgentStateBuilder is one of the most important building blocks for â€œembodied agentsâ€ â€” agents that understand their environment, not just respond to messages.

### Note: 
Your AgentStateBuilder must return a hash that matches the expected LangGraph State object in Python. If you customize fields in Rails, make sure to extend the State class in Python as well.

### Additional Resources: 
!(LangGraph's guide to custom agent states)[https://langchain-ai.github.io/langgraph/tutorials/get-started/5-customize-state/]